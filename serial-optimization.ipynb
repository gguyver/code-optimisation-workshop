{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec6f130",
   "metadata": {},
   "source": [
    "# Serial Optimization\n",
    "How do you optimise serial code? We cover some of the techniques that you might use for serial optimization in Python: \n",
    "1. Vectorization\n",
    "2. Memoization\n",
    "3. Compilation\n",
    "\n",
    "## Vectorization\n",
    "Because Python is an interpreted language - i.e. each line is dispatched to an interpreter program to interpret and execute - there can be a lot of overhead compared to compiled programs. Python needs to check variable types and use the correct functions for the inputs, because these are not necessarily specified. As a result, when you're using Python for large datasets or for long loops, it can pay to implement vectorization.\n",
    "\n",
    "Vectorization essentially increases memory locality, and allows the CPU to use SIMD instructions.  Single Instruction, Multiple Data (SIMD) instructions - these allow the same instruction to be performed on multiple cells of data simultaneously. There is therefore much less overhead per operation, providing large speedups. Improving memory locality also reduces the overhead of dereferencing lots of values that are in lots of different places in memory - contiguous memory blocks that contain all the data you need are loaded on to the CPU instead.\n",
    "\n",
    "Consider the following examples. The first uses base Python to generate a list of integers using a for loop. The second does the same, but uses `numpy` to vectorize the calculation. The `%%timeit` readouts show a large speed increase in the second example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a127ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_ints():\n",
    "  result = []\n",
    "  for x in range(1_000_000):\n",
    "    result.append(x * 2)\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8c0a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.1 ms ± 159 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit double_ints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e887ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263669b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_double_ints():\n",
    "  ints = np.arange(1_000_000)\n",
    "  return ints * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b59c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert double_ints() == np_double_ints().tolist(), \"Results do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c12b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457 μs ± 8.19 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np_double_ints()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f804c",
   "metadata": {},
   "source": [
    "We see a large speed increase in the second example, which uses `numpy` to vectorize the calculation.\n",
    "\n",
    "### Vectorization Exercises\n",
    "The follow code calculates $\\pi$ using Monte Carlo integration. Answer the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef054aa",
   "metadata": {},
   "source": [
    "The following code, which calculates pi using Monte Carlo integration, is provided. Answer the following questions:\n",
    "1. Is it correct?\n",
    "2. How long does it take to run?\n",
    "3. Where is the most time taken, cumulatively?\n",
    "\n",
    "Then:\n",
    "1. Vectorize the code\n",
    "2. Verify the outputs\n",
    "3. Measure any speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff424d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def monte_carlo_pi(num_samples):\n",
    "    inside_circle = 0\n",
    "    for _ in range(num_samples):\n",
    "        x, y = random.uniform(-1, 1), random.uniform(-1, 1)\n",
    "        if x**2 + y**2 <= 1:\n",
    "            inside_circle += 1\n",
    "    return (inside_circle / num_samples) * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372fca2",
   "metadata": {},
   "source": [
    "**Q1.1: Is `monte_carlo_pi()` correct? At what number of samples are you accurate to three digits?**\n",
    "\n",
    "<details>\n",
    "<summary>I need a hint</summary>\n",
    "Run the function with varying `num_samples` and decide whether, as `num_samples` increases, the output approaches 3.1415\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b6e3f",
   "metadata": {},
   "source": [
    "**Q1.2: How long does the function take to run, on average, when `num_samples = 1_000_000`? How does this scale as you vary the number of samples**\n",
    "\n",
    "<details>\n",
    "<summary>I need a hint</summary>\n",
    "\n",
    "Use the `time` module or use `%timeit`\n",
    "<details>\n",
    "<summary>I need a bigger hint</summary>\n",
    "\n",
    "Write a wrapper function which runs and times the function.\n",
    "<details>\n",
    "<summary>Give me the code</summary>\n",
    "\n",
    "```{Python}\n",
    "def pi_time(n):\n",
    "    import time\n",
    "    start = time.time()\n",
    "    out = monte_carlo_pi(n)\n",
    "    end = time.time()\n",
    "    return (out, end - start)\n",
    "```\n",
    "</details>\n",
    "</details>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c75e57",
   "metadata": {},
   "source": [
    "\n",
    "**Q1.3: What functions are called most in `monte_carlo_pi()`?**\n",
    "\n",
    "<details>\n",
    "<summary>I need a hint</summary>\n",
    "\n",
    "Use `cProfile`\n",
    "<details>\n",
    "<summary>I need a bigger hint</summary>\n",
    "\n",
    "Either use `%prun` magic, or call `cProfile()` directly.\n",
    "<details>\n",
    "<summary>Give me the code</summary>\n",
    "\n",
    "```{Python}\n",
    "%prun monte_carlo_pi(10_000_000)\n",
    "```\n",
    "\n",
    "OR\n",
    "\n",
    "```{Python}\n",
    "import cProfile\n",
    "cProfile.run(\"monte_carlo_pi(1_000_000)\")\n",
    "```\n",
    "</details>\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac57355",
   "metadata": {},
   "source": [
    "**Q1.4: Where is the most time taken in `monte_carlo_pi()`, cumulatively?**\n",
    "\n",
    "<details>\n",
    "<summary>I need a hint</summary>\n",
    "\n",
    "You want to know which line takes most time.\n",
    "<details>\n",
    "<summary>I need a bigger hint</summary>\n",
    "\n",
    "Use `line_profiler` or `%lprun`.\n",
    "<details>\n",
    "<summary>Give me the code</summary>\n",
    "\n",
    "```{Python}\n",
    "%load_ext line_profiler\n",
    "%lprun -f monte_carlo_pi monte_carlo_pi(10_000_000)\n",
    "```\n",
    "</details>\n",
    "</details>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b8532",
   "metadata": {},
   "source": [
    "\n",
    "**Q1.5: Can you speed up the function?**\n",
    "\n",
    "<details>\n",
    "<summary>I need a hint</summary>\n",
    "\n",
    "Previous results should have shown most of the time is taken generating random numbers, and checking whether the random point is inside a circle. Can you vectorise either of these?\n",
    "<details>\n",
    "<summary>I need a bigger hint</summary>\n",
    "\n",
    "`numpy` has functions that vectorise random number generation, and allows you to vectorise exponentiation.\n",
    "<details>\n",
    "<summary>Give me the code</summary>\n",
    "\n",
    "```{Python}\n",
    "def monte_carlo_pi_numpy(num_samples):\n",
    "  x, y = np.random.uniform(-1, 1, (2, num_samples)) # vectorised random number generation\n",
    "  pi = 4 * np.mean(x**2 + y**2 <= 1) # perform check simultaneously on all datav`\\` has functions that vectorise random number generation, as wend allows you to vectorise exponentiation.pnumpy\n",
    "  return pi\n",
    "```\n",
    "</details>\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1530d9",
   "metadata": {},
   "source": [
    "\n",
    "**Q1.6: Is your edited function correct? Is it faster? Are there any other ways you can think of to speed it up?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193e991",
   "metadata": {},
   "source": [
    "## Memoization\n",
    "Memoization is a technique to cache results when they're calculated so they can be quickly retrieved when the same input is called. It avoids expensive computation of the same results again and again.\n",
    "\n",
    "Let's remind ourselves of the function we defined previously to calculate the $n^{th}$ number of the Fibonacci sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a0c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if n <= 2:\n",
    "        return 1\n",
    "    return fib(n - 1) + fib(n - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ed1aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894 ms ± 5.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fib(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058fdb1",
   "metadata": {},
   "source": [
    "On our computer, `fib(35)` takes 892 ms on average.\n",
    "\n",
    "We can implement a cache simply ourselves, using dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fa41eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "def fib_cache(n):\n",
    "    if n in cache:\n",
    "        return cache[n]\n",
    "    if n < 2:\n",
    "        result = n\n",
    "    else:\n",
    "        result = fib(n-1) + fib(n-2)\n",
    "    cache[n] = result\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "601a3342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.4 ns ± 0.416 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "assert fib(35) == fib_cache(35), \"Cached result does not match non-cached result!\"\n",
    "%timeit fib_cache(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0512b31",
   "metadata": {},
   "source": [
    "On our computer, calling `fib_cache(35)` took an average of 61 nanoseconds. Merely implementing a basic cache resulted in approximately a 1-million-fold speedup.\n",
    "\n",
    "Due to the recursive nature of this function, the speedup achieved will be greater a n increases, due to the greater number of avoided computations as n grows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda679b",
   "metadata": {},
   "source": [
    "We can also use the `functools` module, which comes with Python and provides the function decorator `@lru_cache`. LRU stands for Least Recently Used - when the cache hits its size limit it removes the least recently used data to make room for the new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25eac273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def fib_lru(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3612a294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 ns ± 532 ns per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fib_lru(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d9d4a",
   "metadata": {},
   "source": [
    "On our computer, the cached version took 257 nanoseconds, *slower* than using our dictionary. Does that hold on your computer? Did you expect it? The functools version avoids code complexity and makes it very simple to cache, however, in this case it does not appear to be as fast as using a dictionary - reiterating the importance of measuring all changes to your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87261ac",
   "metadata": {},
   "source": [
    "### Memoization Exercises\n",
    "\n",
    "We provide a function below that computes the Binomial Coefficient (\"n choose k\") recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c349035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial(n, k):\n",
    "    if k == 0 or k == n:\n",
    "        return 1\n",
    "    return binomial(n - 1, k - 1) + binomial(n - 1, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eed2bd",
   "metadata": {},
   "source": [
    "\n",
    "**Q2.1: How long does this function take with n = 20, k = 10? Explore how the time taken changes as a function of n or k?**\n",
    "\n",
    "<details>\n",
    "<summary>I need a hint</summary>\n",
    "Time the code with a variety of n/k.\n",
    "<details>\n",
    "<summary>I need a bigger hint</summary>\n",
    "Use %timeit, or write a wrapper function.\n",
    "<details>\n",
    "<summary>Give me the code</summary>\n",
    "\n",
    "Edit the code below and explore.\n",
    "```\n",
    "%timeit binomial(20, 10)\n",
    "```\n",
    "</details>\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b3128a",
   "metadata": {},
   "source": [
    "\n",
    "**Q2.2: How many recursive function calls are there with n = 20, k = 10?**\n",
    "\n",
    "<details>\n",
    "<summary>I need a hint</summary>\n",
    "\n",
    "Use `cProfile`.\n",
    "<details>\n",
    "<summary>I need a bigger hint</summary>\n",
    "\n",
    "Either use `cProfile.run()` or `%prun`.\n",
    "<details>\n",
    "<summary>Give me the code</summary>\n",
    "\n",
    "```{Python}\n",
    "%prun binomial(20, 10)\n",
    "```\n",
    "</details>\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a095dc",
   "metadata": {},
   "source": [
    "\n",
    "**Q2.3 Implement memoization. How fast is the function with the same inputs you tested before? How many function calls are there?**\n",
    "\n",
    "<details>\n",
    "<summary>I need a hint</summary>\n",
    "\n",
    "Cache the results if not already in the cache.\n",
    "<details>\n",
    "<summary>I need a bigger hint</summary>\n",
    "\n",
    "Either use a dictionary cache, or `@lru_cache` from `functools`, then time it and use `cProfile`.\n",
    "<details>\n",
    "<summary>Give me the code</summary>\n",
    "\n",
    "```{Python}\n",
    "@lru_cache(maxsize=None)\n",
    "def binomial(n, k):\n",
    "    if k == 0 or k == n:\n",
    "        return 1\n",
    "    return binomial(n - 1, k - 1) + binomial(n - 1, k)\n",
    "\n",
    "%timeit binomial(20, 10)\n",
    "\n",
    "%prun binomial(20, 10)\n",
    "```\n",
    "</details>\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba969b3",
   "metadata": {},
   "source": [
    "## Compilation of functions\n",
    "Python, as an interpreted language, has many overheads as we've discussed. To gain code flexibility and speed of implementation, the language had to make many dynamic checks as code is interpreted. The `CPython` interpreter is well implemented, and these checks are individually fairly fast, but over millions of computations the overhead adds up. In addition, there are implementation details that can simply make speedy code impossible - such as Python lists being arrays of pointers meaning every loop over them involves fetching data twice (get the pointer, then get the data where the pointer points to).\n",
    "\n",
    "There are, however, ways of stepping around the interpreter, and compiling our code ourselves for use in Python. The longest running and most mature method of this is `Cython`, which involves learning a small amount of `C` and setting up a toolchain. We will not be covering that, but if you're interested I encourage you to check it out at https://cython.org/.\n",
    "\n",
    "We will cover the `Numba` package. `Cython` is an Ahead-Of-Time (AOT) compiler - you compile your function(s) before using, creating a static library that can instantly be used. In comparison, `Numba` is a Just-In-Time (JIT) compiler - when your function is first called it will compile the function then, and *future* uses of that function will benefit from the compiled version. The first use, then, will be slow due to the compilation, with all subsequent calls being (hopefully) much faster.\n",
    "\n",
    "If you're using `Numba`, you simply add a decorator and away we go. There are two decorators to consider, because `Numba` has a `nopython` mode. In `nopython` mode the function is compiled to machine code without using the Python interpreter *at all* - however, if this is not possible it fails. Avoiding all the interpreter overhead is often worth it, though. \n",
    "\n",
    "- `@jit()` - tells `Numba` that you want this function to be compiled. It will try to use `nopython`, but if it fails it will fall back to using the python interpreter. Use `@jit(nopython=True)` to enforce `nopython` mode.\n",
    "- `@njit()` - tell `Numba` to compile the function in `nopython` mode.\n",
    "\n",
    "So, lets start using `Numba`. Below we code a Sieve of Eratosthenes using `numpy` to find all primes up to a number `n`. For a primer on the Sieve of Eratosthenes, read the [wikipedia page](https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cb4f883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289 μs ± 2.83 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def sieve_primes(n):\n",
    "    is_prime = np.ones(n + 1, dtype=np.uint8) # Create a boolean array\n",
    "    is_prime[:2] = 0  # 0 and 1 are not prime numbers\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if is_prime[i] == 1:\n",
    "            is_prime[i*i:n+1:i] = 0 # Mark multiples of i as non-prime\n",
    "    return np.where(is_prime)[0] # Get indices of True values, which are the prime numbers\n",
    "\n",
    "assert len(sieve_primes(10000)) == 1229, \"sieve_primes did not return expected number of primes!\"\n",
    "\n",
    "%timeit sieve_primes(100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b36df",
   "metadata": {},
   "source": [
    "On our computer, the sieve of eratosthenes took 161 microseconds on average, when n = 100,000. \n",
    "\n",
    "Adding the `@jit` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c6f2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit(nopython = True)\n",
    "def sieve_primes_numba(n):\n",
    "    is_prime = np.ones(n + 1, dtype=np.uint8) # Create a boolean array\n",
    "    is_prime[:2] = 0  # 0 and 1 are not prime numbers\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if is_prime[i] == 1:\n",
    "            is_prime[i*i:n+1:i] = 0 # Mark multiples of i as non-prime\n",
    "    return np.where(is_prime)[0] # Get indices of True values, which are the prime numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10b49e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 μs ± 10.3 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "assert len(sieve_primes_numba(10000)) == 1229, \"sieve_primes did not return expected number of primes!\"\n",
    "\n",
    "%timeit sieve_primes_numba(100000) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e0e80",
   "metadata": {},
   "source": [
    "On our computer, simply adding the decorator leads to an average speed of 196 microseconds, approximately a 1/3rd speedup for essentially no effort. Compilation often results in much faster speedups, however, this implementation already used vectorised operations, and the Sieve of Eratosthenes is already fairly optimal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eba7b0",
   "metadata": {},
   "source": [
    "### Compilation exercises\n",
    "\n",
    "We revisit here the Julia Set code from the profiling exercises. If you've forgotten them, take a moment to refamiliarise yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db12b37",
   "metadata": {},
   "source": [
    "\n",
    "**Q3.1 Remind yourself, how fast was the `calc_z_serial_python()` function before?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6201f7",
   "metadata": {},
   "source": [
    "\n",
    "**Q3.2 Use Numba to JIT compile the function. Try with and without nopython mode. How fast is it now?**\n",
    "\n",
    "<details>\n",
    "<summary>I need a hint</summary>\n",
    "\n",
    "Edit the code in the `julia_set.py` file. Use the decorators mentioned and time the use of the function.\n",
    "<details>\n",
    "<summary>I need a bigger hint</summary>\n",
    "\n",
    "Use `@jit()` or `@njit()` on the `calc_z_serial_python()` function, and call the code from the terminal. \n",
    "<details>\n",
    "<summary>Give me the code</summary>\n",
    "\n",
    "```{Python}\n",
    "@jit\n",
    "def calc_z_serial_python(maxiter, zs, c):\n",
    "  #' Calculate the Julia set for a given set of complex numbers and a constant c.\n",
    "  output = [0] * len(zs)\n",
    "  for i in range(len(zs)):\n",
    "    z = zs[i]\n",
    "    n = 0\n",
    "    while abs(z) <= 2 and n < maxiter:\n",
    "      z = z * z + c\n",
    "      n += 1\n",
    "    output[i] = n\n",
    "  return output\n",
    "```\n",
    "\n",
    "In the CLI:\n",
    "\n",
    "```{python}\n",
    "python julia_set.py\n",
    "```\n",
    "</details>\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ec1d7",
   "metadata": {},
   "source": [
    "\n",
    "**Q3.3 How long does the compiled function take on the first run? How long on the second?**\n",
    "\n",
    "<details>\n",
    "<summary>I need a hint</summary>\n",
    "\n",
    "Edit the code in the `julia_set.py` file to call the function once or twice. Time them.\n",
    "<details>\n",
    "<summary>I need a bigger hint</summary>\n",
    "\n",
    "You can add time points before and after running the function in `run_julia_set()` Then call `run_julia_set()` twice in `__main__`. \n",
    "<details>\n",
    "<summary>Give me the code</summary>\n",
    "\n",
    "```{Python}\n",
    "  start = time.time()\n",
    "  output = calc_z_serial_python(max_iterations, zs, CONSTVAL) # second run, fully compiled\n",
    "  end = time.time()\n",
    "\n",
    "\n",
    "  ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  run_julia_set(desired_width = 1000, max_iterations = 300)\n",
    "  run_julia_set(desired_width = 1000, max_iterations = 300)\n",
    "```\n",
    "\n",
    "In the CLI:\n",
    "\n",
    "```{python}\n",
    "python julia_set.py\n",
    "```\n",
    "</details>\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998b26b",
   "metadata": {},
   "source": [
    "\n",
    "**Q3.4 Does `run_julia_set()` still spend the majority of its time in the `calc_z_serial_python()` function?**\n",
    "\n",
    "<details>\n",
    "<summary>I need a hint</summary>\n",
    "\n",
    "Use line profiling.\n",
    "<details>\n",
    "<summary>I need a bigger hint</summary>\n",
    "\n",
    "Add the `@profile` decorator to the `run_julia_set()` function and run from the CLI.\n",
    "<details>\n",
    "<summary>Give me the code</summary>\n",
    "\n",
    "```{Python}\n",
    "from line_profiler import profile\n",
    "...\n",
    "...\n",
    "@profile\n",
    "def run_julia_set(desired_width, max_iterations):\n",
    "  ...\n",
    "```\n",
    "\n",
    "In the CLI:\n",
    "\n",
    "```{python}\n",
    "LINE_PROFILE=1 python julia_set.py\n",
    "```\n",
    "</details>\n",
    "</details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e798778",
   "metadata": {},
   "source": [
    "**Q3.5 Would you use compilation even though we only (in this example) call the compiled function once?**\n",
    "\n",
    "<details>\n",
    "<summary>My thoughts</summary>\n",
    "\n",
    "On my computer, compiling the `calc_z_serial_python()` function means the function takes 1.02 seconds (including compilation) rather than 3.23 seconds, a 3-fold speedup even with the added compilation time. Post-compilation, it takes 0.76 seconds per call. However, compiling `calc_complex_numbers()` adds more overhead - with no compilation the function takes 0.09 seconds, with compilation overhead it takes 0.23 seconds, and post-compilation it takes 0.04 seconds. If I knew I would only call this once, I'd compile the first function but not the second.\n",
    "\n",
    "Note that if you *run the script* multiple times, but the script only runs the function once, you incur the compilation cost multiple times as well. There is no substitute for measuring.\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
